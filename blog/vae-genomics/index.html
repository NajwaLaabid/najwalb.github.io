<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Variational Autoencoders for Modeling Single-Cell Data | Najwa Laabid</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="This is the first of a series of tutorials presenting variational autoencoders (VAEs) to an audience of bioinformaticians. This post discusses the motivation behind VAEs and their mathematical basis within the context of modeling single-cell data. A following tutorial will cover the implementation of a simple VAE for modeling single-cell RNA sequencing (sc-RNA-seq) data as an example.
Some sources that helped make this tutorial are Diederik Kingma&rsquo;s original paper, Carl Doersch&rsquo;s tutorial, Andriy Mnih&rsquo;s Deepmind x UCL lecture, and a number of online blogs focusing on VAEs applied to computer vision (Keng&rsquo;s and Jaan&rsquo;s being my favorite).">
    <meta name="generator" content="Hugo 0.91.2" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="Variational Autoencoders for Modeling Single-Cell Data" />
<meta property="og:description" content="This is the first of a series of tutorials presenting variational autoencoders (VAEs) to an audience of bioinformaticians. This post discusses the motivation behind VAEs and their mathematical basis within the context of modeling single-cell data. A following tutorial will cover the implementation of a simple VAE for modeling single-cell RNA sequencing (sc-RNA-seq) data as an example.
Some sources that helped make this tutorial are Diederik Kingma&rsquo;s original paper, Carl Doersch&rsquo;s tutorial, Andriy Mnih&rsquo;s Deepmind x UCL lecture, and a number of online blogs focusing on VAEs applied to computer vision (Keng&rsquo;s and Jaan&rsquo;s being my favorite)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://najwalaabid.github.io/blog/vae-genomics/" /><meta property="article:section" content="blog" />

<meta property="article:modified_time" content="2022-02-04T15:41:03+02:00" />

<meta itemprop="name" content="Variational Autoencoders for Modeling Single-Cell Data">
<meta itemprop="description" content="This is the first of a series of tutorials presenting variational autoencoders (VAEs) to an audience of bioinformaticians. This post discusses the motivation behind VAEs and their mathematical basis within the context of modeling single-cell data. A following tutorial will cover the implementation of a simple VAE for modeling single-cell RNA sequencing (sc-RNA-seq) data as an example.
Some sources that helped make this tutorial are Diederik Kingma&rsquo;s original paper, Carl Doersch&rsquo;s tutorial, Andriy Mnih&rsquo;s Deepmind x UCL lecture, and a number of online blogs focusing on VAEs applied to computer vision (Keng&rsquo;s and Jaan&rsquo;s being my favorite).">
<meta itemprop="dateModified" content="2022-02-04T15:41:03+02:00" />
<meta itemprop="wordCount" content="2017">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Variational Autoencoders for Modeling Single-Cell Data"/>
<meta name="twitter:description" content="This is the first of a series of tutorials presenting variational autoencoders (VAEs) to an audience of bioinformaticians. This post discusses the motivation behind VAEs and their mathematical basis within the context of modeling single-cell data. A following tutorial will cover the implementation of a simple VAE for modeling single-cell RNA sequencing (sc-RNA-seq) data as an example.
Some sources that helped make this tutorial are Diederik Kingma&rsquo;s original paper, Carl Doersch&rsquo;s tutorial, Andriy Mnih&rsquo;s Deepmind x UCL lecture, and a number of online blogs focusing on VAEs applied to computer vision (Keng&rsquo;s and Jaan&rsquo;s being my favorite)."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
      <div class="bg-black">
          <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Najwa Laabid
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/about-me/" title="About me page">
              About me
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/blog/" title="Blog page">
              Blog
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
    <a href="https://twitter.com/__najwalb" target="_blank" class="twitter ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Twitter link" rel="noopener" aria-label="follow on Twitter——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:{{ .fill }};"/></svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>
  
    <a href="https://github.com/NajwaLaabid" target="_blank" class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel="noopener" aria-label="follow on GitHub——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>
  
    <a href="https://www.linkedin.com/in/najwa-laabid/" target="_blank" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:{{ .fill }};"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>
  
</div>
    </div>
  </div>
</nav>

          
          <script>
 MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } });
 MathJax = {
     tex: {
         inlineMath: [['$', '$'], ['\\(', '\\)']]
     },
     svg: {
         fontCache: 'global'
     }
 };
</script>

<script src="http://najwalaabid.github.io/js/mathjax-config.js"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

          
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        BLOG
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
      
      <a href="https://twitter.com/share?url=http://najwalaabid.github.io/blog/vae-genomics/&amp;text=Variational%20Autoencoders%20for%20Modeling%20Single-Cell%20Data" class="ananke-social-link twitter no-underline" aria-label="share on Twitter">
        
        <span class="icon"> <svg style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:{{ .fill }};"/></svg>
</span>
        
      </a>
    
      
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://najwalaabid.github.io/blog/vae-genomics/&amp;title=Variational%20Autoencoders%20for%20Modeling%20Single-Cell%20Data" class="ananke-social-link linkedin no-underline" aria-label="share on LinkedIn">
        
        <span class="icon"> <svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:{{ .fill }};"/>
</svg>
</span>
        
      </a>
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Variational Autoencoders for Modeling Single-Cell Data</h1>
      
      <p class="tracked">
          By <strong>
          
              Najwa Laabid
          
          </strong>
      </p>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2022-02-04T15:41:03+02:00">February 4, 2022</time>
      

      
      
        <span class="f6 mv4 dib tracked"> - 10 minutes read </span>
        <span class="f6 mv4 dib tracked"> - 2017 words </span>
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>This is the first of a series of tutorials presenting variational autoencoders (VAEs) to an audience
of bioinformaticians.
This post discusses the motivation behind VAEs and their mathematical basis within the context of modeling single-cell data.
A following tutorial will cover the implementation of a simple VAE for modeling single-cell RNA sequencing (sc-RNA-seq) data as an example.</p>
<p>Some sources that helped make this tutorial are Diederik Kingma&rsquo;s <a href="https://arxiv.org/abs/1312.6114">original paper</a>, Carl Doersch&rsquo;s
<a href="https://arxiv.org/abs/1606.05908">tutorial</a>, Andriy Mnih&rsquo;s Deepmind x UCL <a href="https://www.youtube.com/watch?v=7Pcvdo4EJeo&amp;ab_channel=DeepMind">lecture</a>,
and a number of online blogs focusing on VAEs applied to computer vision (<a href="https://bjlkeng.github.io/posts/variational-autoencoders/">Keng&rsquo;s</a> and <a href="https://jaan.io/what-is-variational-autoencoder-vae-tutorial/">Jaan&rsquo;s</a> being my favorite).</p>
<h2 id="generative-modeling">Generative modeling</h2>
<h3 id="latent-space-modeling">Latent space modeling</h3>
<p>Generative modeling describes the probabilistic process of generating an observation.
One approach to generative modeling is latent space modeling, which assumes that the observed features are generated by a smaller set of
unobserved (i.e. \(\textit{latent}\)) variables.
These variables, often abstract and difficult to interpret, are seen as encoding a meaningful internal representation of high dimensional data.
Figure <a href="#figure--fig:plate-model">1</a> shows a graphical representation of a latent space model in which unobserved variables \(Z\) generate observed
variables \(X\), and the whole process is repeated \(N\) times (to generate \(N\) samples).</p>
<p><a id="figure--fig:plate-model"></a></p>
<figure><img src="/ox-hugo/plate-model.png"
         alt="Figure 1: A graphical representation of a latent space model." width="50%" height="50%"/><figcaption>
            <p><span class="figure-number">Figure 1: </span>A graphical representation of a latent space model.</p>
        </figcaption>
</figure>

<p>To illustrate the usefulness of latent variables, let us look at the process of studying <a href="https://en.wikipedia.org/wiki/Transcription_(biology)">biological transcription</a>.
We can study the phenotypical differences between groups of cells by comparing
the counts of their expressed genes. If we define a random variable to model the mRNA
counts observed for each gene, we would need to approximate the parameters of around \(10\,000\) marginal distributions
in addition to defining their correlation structure. Not only is this task computationally challenging,
but large variations between transcript counts can be due to small variations in a lower dimensional space.
Instead, we can define 20 latent variables capturing the key directions in which the sequenced cells differ
in their phenotypes. This lower dimensional space is simpler to understand and, if computed well, offers a more
intuitive way of interpreting biological differences compared to the original count space.</p>
<p>From a generative modeling persepctive, we say that these latent variables \(\textit{generate}\) the observed measurements.
When modeling the count data within this paradigm, we are interested in learning two things: 1) the latent variables (which are random variables, therefore expressed as probability distributions),
and 2) the parameters of the generative process (which we consider as single point estimates in this tutorial).
Latent variables define a lower dimensional space where we can perform
downstream analysis tasks, like inferring the branching trajectory of cellular development,
cell clustering using UMAP, etc. The generative parameters quantify the process of transcription and
offer us a way to generate count samples similar to the observed ones.</p>
<p>Next, we will look at a mathematical formulation of this modeling paradigm.</p>
<h3 id="mathematical-formulation-of-latent-space-modeling">Mathematical formulation of latent space modeling</h3>
<p>We would like to model biological transcription using mRNA transcript counts obtained from sc-RNA-seq.
The input data is an \(N \times G\) count matrix \(D\), where \(N\) is the number of cells sequenced, and \(G\) is the number of
genes observed. The matrix typically contains tens of thousands of genes and hundreds of thousands of cells.
We are interested in modeling the count of transcripts per gene across cells.
We therefore define a vector of random variables \(X\) where each variable represents the counts per one gene.
We would like to learn the parameters of the multi-variate distribution of \(X\).
We call \(Z\) the vector of latent variables used in this model.</p>
<p>As mentioned earlier, we are interested in learning: 1) the distribution of latent variables \(Z\),
and 2) the parameters of the generating distribution \(P(X)\).</p>
<p>For the first task, we can use Bayes rule to infer the posterior, as shown in equation \(\ref{eq:posterior}\):</p>
<p>\begin{equation}
\label{eq:posterior}
p_{\theta}(Z|X) = \frac{p_{\theta}(X|Z)p_{\theta}(Z)}{p_{\theta}(X)}
\end{equation}</p>
<p>\begin{equation}
\label{eq:evidence}
p_{\theta}(X) = \int p_{\theta}(X|Z) p_{\theta}(Z) dZ
\end{equation}</p>
<p>\(p_{\theta}(X|Z)\) is known as the likelihood. We know it from the data. \(p_{\theta}(Z)\) is called the prior.
It captures any assumptions we have about the abstract latent space. It is defined as part of the model assumptions.
\(p_{\theta}(X)\) is the marginal likelihood or evidence. It can be computed from the likelihood and prior
using the law of total probability (equation \(\ref{eq:evidence}\)). Parameters \(\theta\) characterize the generative process. We would like
to learn them alongside the posterior \(p_{\theta}(Z|X)\). Note that learning the posterior in this context means generating a distribution over possible
latent values \(Z\) for each data point \(X\).</p>
<p>Unfortunately, \(p_{\theta}(X)\) only has a closed form for conjugate likelihoods
(i.e., likelihoods which when multiplied by a given prior, return a posterior of the same family as the prior).
Gaussian likelihoods and priors are an example of this scenario. However, Gaussian likelihoods are not always a good fit
for real world situations. For example, sc-RNA-seq data is better fitted with a Negative Binomial (NB)
distribution to account for the overdispersion of the counts per gene. The NB distribution does not have a conjugate prior \(p_{\theta}(Z)\),
which makes equation \(\ref{eq:evidence}\) and consequently equation \(\ref{eq:posterior}\) intractable.
An alternative to computing the posterior analytically is to approximate it, as discussed in the next section.</p>
<h3 id="variational-bayes-for-approximating-the-posterior">Variational Bayes for approximating the posterior</h3>
<p>Variational inference is one popular approach for approximating the posterior.
It is an alternative to sampling based methods, like <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo</a>, which often require multiple \(Z\) samples per data point
and therefore do not scale to large datasets.</p>
<p>Variational Inference aims to approximate the posterior as closely as possible by a distribution \(q_{\phi}(Z|X)\)
(sometimes known as a \(\textit{recognition model}\) or \(\textit{variational distribution}\)).
We can learn the parameters \(\phi\) (called \(\textit{variational parameters}\)) alongside the generative parameters \(\theta\).
This closeness between the two distributions is captured by the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback-Liebler divergence</a> as shown in equation \(\ref{eq:kl_divergence}\):</p>
<p>\begin{equation}
\label{eq:kl_divergence}
\begin{aligned}
D[q_{\phi}(Z|X)||p_{\theta}(Z|X)] &amp;= \int q_{\phi}(Z|X) log[\frac{q_{\phi}(Z|X)}{p_{\theta}(Z|X)}] dZ \\
&amp;= E_{Z \sim q_{\phi}} [log \, q_{\phi}(Z|X) - log \, p_{\theta}(Z|X)]  \\
\end{aligned}
\end{equation}</p>
<p>We replace \(p_{\theta}(Z|X)\) using Bayes rule (recall equation \(\ref{eq:posterior}\)):</p>
<p>\begin{equation}
\label{eq:kl_divergence_2}
\begin{aligned}
D[q_{\phi}(Z|X)||p_{\theta}(Z|X)]   &amp;= E_{Z \sim q_{\phi}} [log \, q_{\phi}(Z|X) - log \, p_{\theta}(X|Z) - log \, p_{\theta}(Z) + log \, p_{\theta}(X)]  \\
&amp;= E_{Z \sim q_{\phi}} [log \, q_{\phi}(Z|X) - log \, p_{\theta}(X|Z) - log \, p_{\theta}(Z)] + log \, p_{\theta}(X)  \\
&amp;= E_{Z \sim q_{\phi}} [log Q(Z|X) - log \, p_{\theta}(X|Z) - log \, p_{\theta}(Z)] + log \, p_{\theta}(X)  \\
\end{aligned}
\end{equation}</p>
<p>We rearrange equation \(\ref{eq:kl_divergence_2}\) using the expected value form of the KL-divergence on the last line to get:</p>
<p>\begin{equation}
\label{eq:objective_simplified}
\begin{aligned}
log \, p_{\theta}(X) - D[q_{\phi}(Z|X)||p_{\theta}(Z|X)] &amp;= - E_{Z \sim q_{\phi}} [log \, q_{\phi}(Z|X) - log \, p_{\theta}(X|Z) - log \, p_{\theta}(Z)] \\
&amp;= E_{Z \sim q_{\phi}} [log \, p_{\theta}(X|Z) + log \, p_{\theta}(Z) - log \, q_{\phi}(Z|X)] \\
&amp;= E_{Z \sim q_{\phi}} [log \, p_{\theta}(X|Z)] - E_{Z \sim q_{\phi}}[log \, q_{\phi}(Z|X) - log \, p_{\theta}(Z)] \\
&amp;= E_{Z \sim q_{\phi}} [log \, p_{\theta}(X|Z)] - D[q_{\phi}(Z|X)||p_{\theta}(Z)] \\
\end{aligned}
\end{equation}</p>
<p>The left hand side (LHS) of equation \(\ref{eq:objective_simplified}\) combines the two learning objectives of interest:
maximizing \(log \, p_{\theta}(X)\) to learn the generating parameters, and minimizing the KL-divergence \(D[q_{\phi}(Z|X)||p_{\theta}(Z|X)]\) to approximate the posterior.
The right-hand-side (RHS) offers an equivalent expression that does not depend on the intractable integral and can therefore
be learnt using gradient-based algorithms.</p>
<p>We also note here the apparition of the encoding/decoding elements from which the method derives its name.
The probabilistic \(\textit{encoder} \, q_{\phi}(Z|X)\) creates a latent code \(Z\) for a given observed data \(X\).
Similarly, the \(\textit{decoder} \, p_{\theta}(X|Z)\) translates a given code \(Z\) back to the original feature space.</p>
<p>The RHS of equation \(\ref{eq:objective_simplified}\) is often referred to as the Evidence Lower Bound (ELBO),
symbolized by \(\mathcal{L}(\theta, \phi; X)\).
Since \(D[q_{\phi}(Z|X)||p_{\theta}(Z|X)] &gt; 0\),
\(log \, p_{\theta}(X) &gt; \mathcal{L}(\theta, \phi; X) = E_{Z \sim q_{\phi}} [log \, p_{\theta}(X|Z)] - D[q_{\phi}(Z|X)||p_{\theta}(Z)]\).</p>
<p>Variational autoencoders offer a way to optimize this objective using neural networks and the reparametrization trick,
which we review below.</p>
<h2 id="variational-autoencoders">Variational Autoencoders</h2>
<h3 id="auto-encoding-variational-bayes--aevb--algorithm">Auto-encoding Variational Bayes (AEVB) Algorithm</h3>
<p>The main task here is to optimize the variational lower bound \(\mathcal{L}(\theta, \phi ; X)\) with respect to both \(\theta\) and \(\phi\).
The second term of the RHS, \(D[q_{\phi}(Z|X)||p_{\theta}(Z)]\), has a closed-form solution
if we take both \(q_{\phi}(Z|X)\) and \(p_{\theta}(Z)\) to be Gaussian.
This condition is easy to meet since we choose both the prior and the variational distribution ourselves.
This means we can take the derivative of this term and optimize it via stochastic gradient descent.</p>
<p>Finding a suitable estimator for \(E_{Z \sim q_{\phi}} log \, p_{\theta}(X|Z)\) is a little trickier.
The expectation with respect to \(q_{\phi}\) has a high variance (see here for a <a href="https://nbviewer.org/github/gokererdogan/Notebooks/blob/master/Reparameterization%20Trick.ipynb">demonstration</a>).
To resolve this issue, AEVB proposes a \(\textit{reparametrization trick}\) to make the expectation independent of the parameters \(\phi\),
the target of the optimization.
The trick is based on the observation that we can transform samples from one distribution to another one via a deterministic function.</p>
<p>\begin{equation}
\label{eq:reparam_trick}
Z \sim q_{\phi}(Z) \rightarrow Z = g_{\phi}(\epsilon, X)
\end{equation}</p>
<p>with \(\epsilon \sim p(\epsilon)\).
The simplest example of this transformation is shifting and scaling a standard Normal distribution:</p>
<p>\begin{equation}
\label{eq:gaussian_example}
Z \sim \mathcal{N}(\mu, \sigma) \rightarrow Z  = \mu + \sigma * \epsilon
\end{equation}</p>
<p>for \(\epsilon \sim \mathcal{N}(0, I)\). With this transformation in mind, we can write the expectation \(E_{q_{\phi}(Z|X)} [log \, p_{\theta}(X|Z)]\)
with respect to a distribution \(p(\epsilon)\) independent of \(\phi\).</p>
<p>\begin{equation}
\label{eq:rewrite_expectation}
E_{q_{\phi}(Z|X)} [log \, p_{\theta}(X|Z)] \approx E_{p(\epsilon)} [f(g_{\phi}(\epsilon, X)]
\end{equation}</p>
<p>where \(\epsilon \sim p(\epsilon)\) and \(f(Z)\) is \(log \, p_{\theta}(X|Z)\).
The new expectation can be approximated by:</p>
<p>\begin{equation}
\label{eq:expectation_sample}
E_{p(\epsilon)}[log \, p_{\theta}(X|Z)] = \frac{1}{L} \sum_{l=1}^{L} log \, p_{\theta}(X|Z)
\end{equation}</p>
<p>The final expression of the lower bound, with the transformed \(Z\), would therefore be:</p>
<p>\begin{equation}
\label{eq:final_elbo}
\mathcal{L}(\theta, \phi; X) = - D[q_{\phi}(Z|X)||p_{\theta}(Z)] + \frac{1}{L} \sum_{l=1}^{L} log , p_{\theta}(X|Z)
\end{equation}</p>
<p>with \(Z = g_{\phi}(\epsilon, X)\) and \(\epsilon \sim p(\epsilon)\).</p>
<h3 id="the-encoder-and-decoder-as-neural-networks">The Encoder and Decoder as Neural Networks</h3>
<p><a id="figure--fig:training-vae"></a></p>
<figure><img src="/ox-hugo/reparam-trick.png"
         alt="Figure 2: A diagram of a variational auto-encoder (source)."/><figcaption>
            <p><span class="figure-number">Figure 2: </span>A diagram of a variational auto-encoder (<a href="https://bjlkeng.github.io/posts/variational-autoencoders/">source</a>).</p>
        </figcaption>
</figure>

<p>Variational autoencoders are a special instantiation of the AEVB algorithm in which we use neural networks to implement the encoder
\(q_{\phi}(Z|X)\) and decoder \(p_{\theta}(X|Z)\) models.</p>
<p>Figure <a href="#figure--fig:training-vae">2</a> illustrates this idea. We start with the data \(X\), and learn the parameters \(\phi\)
of the encoding distribution (i.e. approximate posterior) \(q_{\phi}(Z|X)\) by minimizing the KL divergence between \(q_{\phi}(Z|X)\)
and the prior \(p_{\theta}(Z)\). We then sample a \(Z\) from the approximate posterior. This \(Z\) is used by the decoder to estimate the parameters
\(\theta\) of \(p_{\theta}(X|Z)\). In this example, we use mean squared error (MSE) to optimize the decoder because we assume \(p_{\theta}(X|Z)\)
follows a multi-variate Gaussian distribution.</p>
<p>Notice that, thanks to the reparametrization trick, we are able to replace sampling by a deterministic function.
We take a sample from a standard normal distribution in the input layer, and shift and scale it using the parameters
learnt by the encoder model. Without the reparameterization trick, we would not be able to backpropagate the derivative of the MSE term
through the sampling layer, and the training of the neural networks via backpropagation would fail.</p>
<h2 id="summary">Summary</h2>
<p>In this tutorial, we covered how generative modeling is useful in defining a lower dimensional space to better understand the variation in single-cell sequencing data.
We also explained the main learning goals when using generative models, namely: 1) infering latent variables
and 2) estimating the parameters of the generative process. We then showed how the AEVB algorithm achieves both goals by defining a low-variance estimator
of the ELBO. This estimator can be trained via stochastic gradient descent thanks to the reparametrization trick.
Finally, we presented variational auto-encoders as an instantiation of AEVB which uses neural networks to implement the encoder and decoder
models.</p>
<p>In the next tutorial, we will see a practical example of how to implement a simple VAE to model sc-RNA-seq data, and how the
distributions recovered from the model can be used for all kinds of downstream biological analyses.</p>
<h2 id="vaes-in-single-cell-analysis-literature">VAEs in single-cell analysis literature</h2>
<p>Below is a non-exhaustive list of methods using VAEs to analyze single-cell data:</p>
<ul>
<li><a href="https://www.nature.com/articles/s41592-018-0229-2">scVI</a> proposes a VAE model to analyze sc-RNA-seq data.</li>
<li><a href="https://www.nature.com/articles/s41592-020-01050-x">totalVI</a> extends scVI to modeling multi-modal RNA and protein datasets.</li>
<li><a href="https://github.com/scvae/scvae">scVAE</a> also focuses on modeling sc-RNA-seq data, but it includes the cell size as a modeling variable.</li>
<li><a href="https://www.biorxiv.org/content/10.1101/631382v1">SISUA</a> uses a semi-supervised VAE model to build latent space representations incorporating both protein and RNA data.</li>
</ul>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://najwalaabid.github.io/" >
    &copy;  Najwa Laabid 2022 
  </a>
    <div>
<div class="ananke-socials">
  
    <a href="https://twitter.com/__najwalb" target="_blank" class="twitter ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Twitter link" rel="noopener" aria-label="follow on Twitter——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:{{ .fill }};"/></svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>
  
    <a href="https://github.com/NajwaLaabid" target="_blank" class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel="noopener" aria-label="follow on GitHub——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>
  
    <a href="https://www.linkedin.com/in/najwa-laabid/" target="_blank" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:{{ .fill }};"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>
  
</div></div>
  </div>
</footer>

  </body>
</html>
